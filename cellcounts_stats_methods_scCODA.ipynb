{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f49f22",
   "metadata": {},
   "source": [
    "# This pynb files contains code for following tasks\n",
    "\n",
    "1. Cell proportion counts\n",
    "\n",
    "2. Linear mixed model for counts/proportions using lme4\n",
    "\n",
    "3. scCODA method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7c9bc",
   "metadata": {},
   "source": [
    "# Cell proportions based on brain region based on granular celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98bb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata \n",
    "\n",
    "### read the anndata after celltype annotation\n",
    "\n",
    "bdata=sc.read_h5ad(\"path/dataset.h5ad\")\n",
    "\n",
    "#### subset the data for neuronal population\n",
    "\n",
    "Neuron=bdata[bdata.obs['major_celltypes'].isin([\"Excitatory\",\"Inhibitory\"])]\n",
    "\n",
    "\n",
    "#### subset the data based on Brain Region\n",
    "\n",
    "BA9=Neuron[Neuron.obs[\"Brain.Region\"] == \"Frontal Cx (BA9)\"]\n",
    "BA7=Neuron[Neuron.obs[\"Brain.Region\"] == \"Precuneous (BA7)\"]\n",
    "BA17=Neuron[Neuron.obs[\"Brain.Region\"] == \"Primary Visual Cx (BA17)\"]\n",
    "\n",
    "\n",
    "#### plot the proportion for each brain region\n",
    "\n",
    "# count the number of occurrences  for each cluster ID\n",
    "count = BA9.obs.groupby(['Disease.Group', 'Author_Annotation']).size()\n",
    "new_df = count.to_frame(name = 'size').reset_index()\n",
    "\n",
    "# Pivot and rename columns\n",
    "freq = new_df.pivot(index='Disease.Group', columns='Author_Annotation')['size']\n",
    "list2 = [\"Ex1\", \"Ex2\", \"Ex3\", \"Ex4\", \"Ex5\", \"Ex6\", \"Ex7\", \"Ex8\", \"Ex9\", \"Ex10\", \"Ex11\", \"Ex12\", \"Ex13\", \"Ex14\", \"Ex15\", \"Ex16\", \"Ex17\", \"Ex18\", \n",
    "         \"In1\", \"In2\", \"In3\", \"In4\", \"In5\", \"In6\", \"In7\", \"In8\", \"In9\", \"In10\", \"In11\", \"In12\", \"In13\", \"In14\", \"In15\", \"In16\", \"In17\", \"In18\", \"In19\"]\n",
    "freq.columns = list2\n",
    "\n",
    "# Normalize\n",
    "percent = freq.div(freq.sum(axis=1), axis=0).T\n",
    "percent['Clusters'] = percent.index\n",
    "\n",
    "# Select Disease.Groups\n",
    "T_new = percent[['low', 'int', 'high', 'Clusters']]\n",
    "\n",
    "# Standard error \n",
    "se_new = T_new[['low', 'int', 'high']].apply(lambda col: np.std(col, ddof=1) / np.sqrt(len(col)), axis=0)\n",
    "\n",
    "# Plot \n",
    "plt.rcParams.update({'font.size': 28})\n",
    "T_new.plot(x='Clusters', kind='bar', figsize=(30, 7), width=0.8, color=['cyan', 'blue', 'red'], \n",
    "           edgecolor='black', capsize=2, title='Proportion of Neuronal Cell Types in BA9')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=5)\n",
    "plt.ylabel(\"Cell Proportion\", fontsize=22)\n",
    "\n",
    "# Error bars\n",
    "x_positions = np.arange(len(T_new['Clusters']))\n",
    "for i, col in enumerate(['low', 'int', 'high']):\n",
    "    plt.errorbar(x_positions + i * 0.3 - 0.3, T_new[col], yerr=se_new[i], fmt='none', color='black', capsize=3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67050cf8",
   "metadata": {},
   "source": [
    "# LMM model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602ca7f",
   "metadata": {},
   "source": [
    "# calculate the proportions based on layer annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7065eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# List unique layer annotation specified in the anndata\n",
    "unique_cell_types = BA9_AllNuc_neurons.obs['layers1'].unique()\n",
    "\n",
    "# List to store rows before creating DataFrame\n",
    "rows = []\n",
    "\n",
    "# Calculate cell proportions per subject per cell type\n",
    "for cell_type in unique_cell_types:\n",
    "    cell_data = BA9_AllNuc_neurons[BA9_AllNuc_neurons.obs['layers1'] == cell_type].obs\n",
    "    total_cells = len(cell_data)\n",
    "    \n",
    "    grouped = cell_data.groupby(['Donor', 'Disease.Group', 'Assay', 'APOE_class', 'Age', 'Sex'])\n",
    "    \n",
    "    for group_keys, group_df in grouped:\n",
    "        subject, disease_group, assay, apoe_class, age, sex = group_keys\n",
    "        proportion = len(group_df) / total_cells\n",
    "        rows.append({\n",
    "            'CellType': cell_type,\n",
    "            'Subject': subject,\n",
    "            'Assay': assay,\n",
    "            'Disease_Group': disease_group,\n",
    "            'APOE_class': apoe_class,\n",
    "            'Age': age,\n",
    "            'Sex': sex,\n",
    "            'Proportion': proportion\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "cell_proportions_df = pd.DataFrame(rows)\n",
    "cell_proportions_df.to_csv(\"path/BA9_AllNuc_neurons_proportions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3c34f",
   "metadata": {},
   "source": [
    "# lme4 mixed model for proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Required Libraries\n",
    "\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "\n",
    "\n",
    "# Step 1: Load and Prepare Data : Input-Proportion data \n",
    "\n",
    "data <- read.csv(\"path/BA9_AllNuc_neurons_proportions.csv\")\n",
    "\n",
    "\n",
    "### adjust age treat them as covraiate\n",
    "data <- data %>%\n",
    "  mutate(\n",
    "    Age = case_when(Age == \"95 and above\" ~ \"95\", TRUE ~ Age),\n",
    "    Age = as.numeric(Age),\n",
    "    Disease_Group = factor(Disease_Group, levels = c(\"low\", \"int\", \"high\")),\n",
    "    Assay = factor(Assay),\n",
    "    APOE_class = factor(APOE_class),\n",
    "    Sex = factor(Sex),\n",
    "    Proportion = pmin(pmax(Proportion, 1e-5), 1 - 1e-5)\n",
    "  ) %>%\n",
    "  filter(!is.na(Age), !is.na(APOE_class), !is.na(Proportion))\n",
    "\n",
    "\n",
    "# Step 2: Fit Unweighted Beta GLMM per Cell Type\n",
    "\n",
    "celltypes <- unique(data$CellType)\n",
    "results <- list()\n",
    "\n",
    "for (ct in celltypes) {\n",
    "  message(\"Processing: \", ct)\n",
    "  subdata <- data %>% filter(CellType == ct) %>% droplevels()\n",
    "  \n",
    "  if (n_distinct(subdata$Subject) < 3) next\n",
    "  \n",
    "  model <- tryCatch({\n",
    "    glmmTMB(\n",
    "      Proportion ~ Disease_Group + Assay + Age + APOE_class + Sex + (1 | Subject),\n",
    "      family = beta_family(link = \"logit\"),\n",
    "      data = subdata\n",
    "    )\n",
    "  }, error = function(e) {\n",
    "    warning(\"Model failed for \", ct, \": \", e$message)\n",
    "    return(NULL)\n",
    "  })\n",
    "  ### dipsly error message\n",
    "\n",
    "\n",
    "  ### model outputs\n",
    "  \n",
    "  if (!is.null(model)) {\n",
    "    coef_summary <- summary(model)$coefficients$cond\n",
    "    result_df <- data.frame(\n",
    "      CellType = ct,\n",
    "      Coefficient = rownames(coef_summary),\n",
    "      Estimate = coef_summary[, \"Estimate\"],\n",
    "      StdError = coef_summary[, \"Std. Error\"],\n",
    "      z_value = coef_summary[, \"z value\"],\n",
    "      p_value = coef_summary[, \"Pr(>|z|)\"],\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    results[[ct]] <- result_df\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# Step 3: Apply FDR Correction\n",
    "\n",
    "\n",
    "combined_results <- bind_rows(results) %>%\n",
    "  mutate(FDR = p.adjust(p_value, method = \"BH\"))\n",
    "\n",
    "\n",
    "# Step 4: Save Results\n",
    "\n",
    "write.csv(combined_results,\n",
    "          \"path/results/BA9_AllNuc_neurons_proportions_LMM_results.csv\",\n",
    "          row.names = FALSE)\n",
    "\n",
    "message(\" Unweighted Beta GLMM complete. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96002f",
   "metadata": {},
   "source": [
    "# Plot LMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd03601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "### read the dataframe for plotting\n",
    "BA9=pd.read_csv(\"/path BA9.csv\")\n",
    "\n",
    "# Sample DataFrame columns\n",
    "Y = BA9['log10_pvalue']\n",
    "X = BA9['z_value']\n",
    "labels = BA9['CellType']\n",
    "p_value = BA9['p_value']\n",
    "log_p_values = -np.log10(p_value)\n",
    "\n",
    "significance_threshold = -np.log10(0.07)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Get unique cell types and assign a distinct color to each\n",
    "unique_celltypes = np.unique(labels)\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "color_dict = {celltype: cmap(i % 20) for i, celltype in enumerate(unique_celltypes)}\n",
    "\n",
    "# Plot and annotate non-significant points\n",
    "for celltype in unique_celltypes:\n",
    "    idx = (labels == celltype) & (log_p_values < significance_threshold)\n",
    "    plt.scatter(\n",
    "        X[idx], log_p_values[idx], marker='o', s=90,\n",
    "        c=[color_dict[celltype]], edgecolor=\"black\", label=celltype\n",
    "    )\n",
    "\n",
    "    # Annotate each non-significant point\n",
    "    for i in np.where(idx)[0]:\n",
    "        x_pos = X[i] + 0.05\n",
    "        y_pos = log_p_values[i]\n",
    "        plt.annotate(\n",
    "            labels[i], (x_pos, y_pos),\n",
    "            fontsize=12, alpha=0.6,\n",
    "            textcoords='offset points', xytext=(5, 0)\n",
    "        )\n",
    "\n",
    "# Plot and annotate significant points in red\n",
    "for i in range(len(X)):\n",
    "    if log_p_values[i] >= significance_threshold:\n",
    "        plt.scatter(\n",
    "            X[i], log_p_values[i],\n",
    "            marker='s', s=100, color='red', edgecolor=\"black\"\n",
    "        )\n",
    "        x_pos = X[i] + 0.05\n",
    "        y_pos = log_p_values[i]\n",
    "        plt.annotate(\n",
    "            labels[i], (x_pos, y_pos),\n",
    "            fontsize=12, fontweight='bold',\n",
    "            textcoords='offset points', xytext=(5, 0)\n",
    "        )\n",
    "\n",
    "# Plot formatting\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.xlabel(\"Z scores\")\n",
    "plt.ylabel(\"-log10(p-value)\")\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.grid(True, linestyle='--', alpha=0.7, color='black')\n",
    "\n",
    "# Legend for cell types\n",
    "plt.legend(title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Save plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"path/BA9_LMM_plot_all.pdf\", format='pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154f03f",
   "metadata": {},
   "source": [
    "# scCODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "scCODA compositional analysis on BA9 subset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# scCODA\n",
    "from sccoda.util import comp_ana as mod\n",
    "from sccoda.util import cell_composition_data as dat\n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def empty_dir(path: str):\n",
    "    \"\"\"Delete contents of a directory without removing the directory.\"\"\"\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    for name in os.listdir(path):\n",
    "        p = os.path.join(path, name)\n",
    "        try:\n",
    "            if os.path.isfile(p) or os.path.islink(p):\n",
    "                os.remove(p)\n",
    "            elif os.path.isdir(p):\n",
    "                shutil.rmtree(p)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {p}: {e}\")\n",
    "\n",
    "\n",
    "def coerce_numeric(series: pd.Series, replace_values=(\"95 or above\",)) -> pd.Series:\n",
    "    s = series.copy()\n",
    "    for v in replace_values:\n",
    "        s = s.replace(v, np.nan)\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def zscore(series: pd.Series) -> pd.Series:\n",
    "    return (series - series.mean()) / series.std(ddof=0)\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"scCODA compositional analysis for BA9.\")\n",
    "    ap.add_argument(\"--h5ad\", required=True, help=\"Path to adata.h5ad\")\n",
    "    ap.add_argument(\"--rootdir\", default=\".\", help=\"Root directory (for relative paths)\")\n",
    "    ap.add_argument(\"--outdir\", default=\"results/BA9_AllNuc_NeuN\", help=\"Output directory\")\n",
    "    ap.add_argument(\"--region\", default=\"Frontal Cx (BA9)\", help=\"Brain region value to keep\")\n",
    "    ap.add_argument(\"--thresholds\", nargs=\"*\", type=int, default=[500], help=\"n_genes lower thresholds\")\n",
    "    ap.add_argument(\"--disease_col\", default=\"Disease.Group\", help=\"Column with disease group\")\n",
    "    ap.add_argument(\"--celltype_col\", default=\"layers1\", help=\"Column with cell-type labels\")\n",
    "    ap.add_argument(\"--group_order\", nargs=\"*\", default=[\"low\", \"int\", \"high\"], help=\"Disease group order\")\n",
    "    ap.add_argument(\"--assay_ref\", default=\"DropSeq\", help=\"Reference level for Assay\")\n",
    "    ap.add_argument(\"--sex_ref\", default=\"F\", help=\"Reference level for Sex\")\n",
    "    ap.add_argument(\"--apoe_ref\", default=\"E3/E3\", help=\"Reference level for APOE_class\")\n",
    "    ap.add_argument(\"--empty_outdir\", action=\"store_true\", help=\"Empty output dir before writing\")\n",
    "    ap.add_argument(\"--neurons_list\", nargs=\"*\", default=None,\n",
    "                    help=\"Explicit list of neuron cell types to plot. \"\n",
    "                         \"If not provided, any cell type starting with 'Ex' will be used.\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    out_dir = os.path.join(args.rootdir, args.outdir)\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    if args.empty_outdir:\n",
    "        empty_dir(out_dir)\n",
    "\n",
    "    # Load and subset to BA9\n",
    "    adata = sc.read_h5ad(os.path.join(args.rootdir, args.h5ad))\n",
    "    if \"Brain.Region\" not in adata.obs.columns:\n",
    "        raise ValueError(\"Brain.Region column not found in .obs\")\n",
    "    adata = adata[adata.obs[\"Brain.Region\"].isin([args.region])].copy()\n",
    "\n",
    "    # Prepare covariates\n",
    "    if args.disease_col not in adata.obs.columns:\n",
    "        raise ValueError(f\"{args.disease_col} not found in .obs\")\n",
    "    adata.obs[\"Disease\"] = adata.obs[args.disease_col].astype(str)\n",
    "\n",
    "    sample_variable = \"Donor\" if \"Donor\" in adata.obs.columns else (\"subject\" if \"subject\" in adata.obs.columns else None)\n",
    "    if sample_variable is None:\n",
    "        raise ValueError(\"Neither 'Donor' nor 'subject' found in .obs\")\n",
    "\n",
    "    if \"Age\" in adata.obs.columns:\n",
    "        adata.obs[\"Age\"] = coerce_numeric(adata.obs[\"Age\"])\n",
    "    else:\n",
    "        adata.obs[\"Age\"] = np.nan\n",
    "\n",
    "    num_cols = adata.obs.select_dtypes(include=[np.number]).columns\n",
    "    if len(num_cols):\n",
    "        imputer_num = SimpleImputer(strategy=\"mean\")\n",
    "        adata.obs[num_cols] = imputer_num.fit_transform(adata.obs[num_cols])\n",
    "\n",
    "    adata.obs[\"Age_z\"] = zscore(adata.obs[\"Age\"])\n",
    "\n",
    "    if \"APOE_class\" in adata.obs.columns:\n",
    "        adata.obs[\"APOE_class\"] = adata.obs[\"APOE_class\"].astype(str).replace(\"nan\", np.nan)\n",
    "    else:\n",
    "        adata.obs[\"APOE_class\"] = np.nan\n",
    "\n",
    "    cat_cols = adata.obs.select_dtypes(include=[\"category\", \"object\"]).columns\n",
    "    if len(cat_cols):\n",
    "        imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "        adata.obs[cat_cols] = imputer_cat.fit_transform(adata.obs[cat_cols])\n",
    "\n",
    "    if \"n_genes\" not in adata.obs.columns:\n",
    "        raise ValueError(\"'n_genes' not found in .obs (needed for threshold filtering)\")\n",
    "    adata.obs[\"n_genes\"] = adata.obs[\"n_genes\"].astype(int)\n",
    "\n",
    "    # Iterate thresholds n_genes threshold\n",
    "    for thr in args.thresholds:\n",
    "        print(f\"\\n=== n_genes > {thr} ===\")\n",
    "        ad_thr = adata[adata.obs[\"n_genes\"] > thr].copy()\n",
    "        if ad_thr.n_obs == 0:\n",
    "            print(\"No cells remain after threshold; skipping.\")\n",
    "            continue\n",
    "\n",
    "        if args.celltype_col not in ad_thr.obs.columns:\n",
    "            raise ValueError(f\"{args.celltype_col} not found in .obs\")\n",
    "\n",
    "        df_obs = ad_thr.obs.copy()\n",
    "\n",
    "        # Counts per donor x cell type\n",
    "        cluster_counts = (\n",
    "            df_obs.groupby([sample_variable, args.celltype_col]).size().reset_index(name=\"cell_count\")\n",
    "        )\n",
    "        cluster_counts_pivot = (\n",
    "            cluster_counts.pivot(index=sample_variable, columns=args.celltype_col, values=\"cell_count\").fillna(0)\n",
    "        )\n",
    "        cluster_counts_pivot = cluster_counts_pivot.astype(int)\n",
    "\n",
    "        # Proportions per donor\n",
    "        df_normalized = cluster_counts_pivot.div(cluster_counts_pivot.sum(axis=1), axis=0)\n",
    "        df_normalized.index.name = sample_variable\n",
    "        df_normalized = df_normalized.reset_index()\n",
    "\n",
    "        # Build scCODA data object\n",
    "        cluster_counts_pivot[sample_variable] = cluster_counts_pivot.index\n",
    "        data_all = dat.from_pandas(cluster_counts_pivot, covariate_columns=[sample_variable])\n",
    "\n",
    "        # Donor-level covariates\n",
    "        sample_obs = df_obs.groupby(sample_variable, as_index=False).first().set_index(sample_variable)\n",
    "        data_all.obs = sample_obs\n",
    "\n",
    "        # Ensure Disease is categorical with specified order\n",
    "        data_all.obs[\"Disease\"] = pd.Categorical(\n",
    "            data_all.obs[\"Disease\"], categories=args.group_order, ordered=True\n",
    "        )\n",
    "\n",
    "        # Save raw proportions by Disease\n",
    "        merged_prop = pd.merge(\n",
    "            data_all.obs[[\"Disease\"]], df_normalized.set_index(sample_variable),\n",
    "            left_index=True, right_index=True, how=\"inner\"\n",
    "        )\n",
    "        merged_prop[\"Donor\"] = merged_prop.index\n",
    "        merged_prop.to_excel(os.path.join(out_dir, f\"{thr}_scCoda_Proportions_All.xlsx\"))\n",
    "\n",
    "        # scCODA model\n",
    "        formula_terms = [\"C(Disease, Treatment('low'))\"]\n",
    "        if \"Sex\" in data_all.obs.columns:\n",
    "            formula_terms.append(f\"C(Sex, Treatment('{args.sex_ref}'))\")\n",
    "        if \"APOE_class\" in data_all.obs.columns:\n",
    "            formula_terms.append(f\"C(APOE_class, Treatment('{args.apoe_ref}'))\")\n",
    "        if \"Assay\" in data_all.obs.columns:\n",
    "            formula_terms.append(f\"C(Assay, Treatment('{args.assay_ref}'))\")\n",
    "        if \"Age_z\" in data_all.obs.columns:\n",
    "            formula_terms.append(\"Age_z\")\n",
    "        formula = \" + \".join(formula_terms) if formula_terms else \"1\"\n",
    "\n",
    "        model = mod.CompositionalAnalysis(\n",
    "            data_all,\n",
    "            formula=formula,\n",
    "            reference_cell_type=\"automatic\"\n",
    "        )\n",
    "\n",
    "        sim_results = model.sample_hmc()\n",
    "        tag = f\"BA9_AllNuc_NeuN_{thr}\"\n",
    "\n",
    "        sim_results.save(os.path.join(out_dir, f\"{tag}_results.pkl\"))\n",
    "        sim_results.credible_effects().to_excel(os.path.join(out_dir, f\"{tag}_credible_effects.xlsx\"))\n",
    "        pd.DataFrame(sim_results.summary()).to_excel(os.path.join(out_dir, f\"{tag}_summary.xlsx\"))\n",
    "\n",
    "        full_results = pd.concat(\n",
    "            [pd.DataFrame(sim_results.credible_effects()), sim_results.effect_df], axis=1\n",
    "        )\n",
    "        full_results.to_excel(os.path.join(out_dir, f\"{tag}_full_results.xlsx\"))\n",
    "\n",
    "        # Barplot (neuronal types)\n",
    "        if args.neurons_list is not None and len(args.neurons_list):\n",
    "            neurons = args.neurons_list\n",
    "        else:\n",
    "            neurons = sorted([c for c in cluster_counts_pivot.columns if isinstance(c, str) and c.startswith(\"Ex\")])\n",
    "\n",
    "        if len(neurons) == 0:\n",
    "            print(\"No neuron cell types detected for barplot; skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        df_norm_long = df_normalized.melt(\n",
    "            id_vars=[sample_variable],\n",
    "            var_name=args.celltype_col,\n",
    "            value_name=\"Proportion\"\n",
    "        )\n",
    "        merged_df = pd.merge(df_norm_long, data_all.obs[[\"Disease\"]], left_on=sample_variable, right_index=True)\n",
    "        merged_df[\"Disease\"] = pd.Categorical(merged_df[\"Disease\"], categories=args.group_order, ordered=True)\n",
    "        plot_df = merged_df[merged_df[args.celltype_col].isin(neurons)].copy()\n",
    "        plot_df[args.celltype_col] = plot_df[args.celltype_col].str.replace(r\":.*\", \"\", regex=True)\n",
    "\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        ax = sns.barplot(\n",
    "            data=plot_df,\n",
    "            x=args.celltype_col,\n",
    "            y=\"Proportion\",\n",
    "            hue=\"Disease\",\n",
    "            ci=\"sd\",\n",
    "            capsize=0.1,\n",
    "            errwidth=1.2,\n",
    "            order=sorted(plot_df[args.celltype_col].unique()),\n",
    "        )\n",
    "        ax.legend(title=\"Disease\")\n",
    "        plt.xticks(rotation=90, ha=\"right\", fontsize=10)\n",
    "        plt.ylabel(\"Proportion\", fontsize=12)\n",
    "        plt.xlabel(args.celltype_col, fontsize=12)\n",
    "        plt.title(\"Proportion of excitatory neuron types by Disease\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"{tag}_barplot.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"\\nDone. Outputs in: {out_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ccebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
